# khai b√°o th∆∞ vi·ªán v√† api_key
import time
from datetime import datetime, timedelta
from plyer import notification
import os
import pandas as pd

os.environ["GOOGLE_API_KEY"] = ""

# text to speech

def noi(x):
    from gtts import gTTS
    from io import BytesIO
    import pygame
    tts = gTTS(text=x, lang="vi")
    mp3_fp = BytesIO()
    tts.write_to_fp(mp3_fp)

    # Ph√°t √¢m thanh

    mp3_fp.seek(0)
    pygame.mixer.init()
    pygame.mixer.music.load(mp3_fp, "mp3")
    pygame.mixer.music.play()

    # Ch·ªù cho ƒë·∫øn khi ph√°t xong

    while pygame.mixer.music.get_busy():
        time.sleep(0.5)
    pygame.mixer.quit()

# nh·∫≠n di·ªán gi·ªçng n√≥i(speech to text)

def nhangiong():
    import pyaudio
    import speech_recognition as sr
    import asyncio
    import base64
    import json
    s = sr.Recognizer()
    with sr.Microphone() as source:
        print("ƒêang l·∫Øng nghe")
        mp3 = s.listen(source)
    vb = s.recognize_google(mp3, language="vi-VN")
    try:
        vb
    except:
        print("Kh√¥ng c√≥ √¢m thanh")
    return vb.lower()
#quay l·∫°i ki·ªÉm tra
def molai():
    txt='xin ch√†o'
    noi("xin ch√†o")
    # ki·ªÉm tra y√™u c·∫ßu
    while True:
        if "hello" or "xin ch√†o" in txt:
                
            noi("xin h·ªèi y√™u c·∫ßu c·ªßa b·∫°n l√† g√¨")
                
            # n√≥i y√™u c·∫ßu
                
            xt =input("y√™u c·∫ßu:")
            if 'x√≥a' in xt:
                hienthi()
                xoa()
            elif 't·∫°m bi·ªát' in xt:
                noi("Ch√†o t·∫°m bi·ªát b·∫°n")
                break
            elif 'h·ªèi ƒë√°p' in xt:
                noi("ƒêang kh·ªüi ƒë·ªông h·ªèi ƒë√°p")
            elif 'xem' in xt:
                noi("ƒêang in l·ªãch tr√¨nh")
                hienthi()
            elif 'gemini' in xt:
                gemini()
            else:
                noi("Xin l·ªói,t√¥i kh√¥ng c√≥ ch·ª©c nƒÉng n√†y")
# x√©t file l·ªãch tr√¨nh
file = "D:/CODER/python/xlsx/lichtrinh.xlsx"

lan_nhac_gan_nhat = {}
# n·∫øu ch∆∞a c√≥,t·∫°o file m·ªõi
if not os.path.exists(file):
    noi("Hi·ªán ch∆∞a c√≥ l·ªãch tr√¨nh, t√¥i s·∫Ω t·∫°o file m·ªõi.")
    df = pd.DataFrame(columns=["ti√™u ƒë·ªÅ", "th·ªùi gian"])
    df.to_excel(file, index=False)
    noi("ƒê√£ t·∫°o xong")
# xem c√≥ ƒëang n·∫±m hay kh√¥ng
import cv2
from ultralytics import YOLO

model = YOLO("yolo11l.pt")

def dang_nam_hien_tai():
    cap = cv2.VideoCapture(0)
    ret, frame = cap.read()
    cap.release()

    if not ret:
        return False

    results = model(frame, verbose=False)[0]

    for box in results.boxes:
        if model.names[int(box.cls[0])] == "person":
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            w = x2 - x1
            h = y2 - y1
            if h > 0 and w / h > 1.4:
                return True

    return False

# ===== TH√îNG B√ÅO =====
def thong_bao(tieu_de, noi_dung):
    notification.notify(
        title=tieu_de,
        message=noi_dung,
        timeout=10
    )
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] {tieu_de}: {noi_dung}")

# ===== KI·ªÇM TRA & NH·∫ÆC =====
def kiem_tra_lich():
    df = pd.read_excel(file)

    # Chu·∫©n ho√° c·ªôt th·ªùi gian (AUTO nh·∫≠n d·∫°ng m·ªçi ƒë·ªãnh d·∫°ng Excel)
    df["thoi_gian"] = pd.to_datetime(
        df["th·ªùi gian"],
        errors="coerce",
    )

    now = datetime.now()

    for _, row in df.iterrows():
        if pd.isna(row["thoi_gian"]):
            continue

        thoi_diem_goc = row["thoi_gian"]
        bat_dau_nhac = thoi_diem_goc - timedelta(minutes=30)

        # Ch·ªâ nh·∫Øc trong kho·∫£ng cho ph√©p
        if not (bat_dau_nhac <= now < thoi_diem_goc):
            continue

        key = f"{thoi_diem_goc}_{row['ti√™u ƒë·ªÅ']}"
        lan_nhac_cuoi = lan_nhac_gan_nhat.get(key)

        if lan_nhac_cuoi is None or now - lan_nhac_cuoi >= timedelta(minutes=5):
            thong_bao(
                f"‚è∞ S·∫ÆP ƒê·∫æN GI·ªú ({thoi_diem_goc.strftime('%H:%M')})",
                f"{row['ti√™u ƒë·ªÅ']}")
            noi("g·∫ßn ƒë·∫øn gi·ªù th·ª±c hi·ªán l·ªãch h√¥m nay r·ªìi")
            if dang_nam_hien_tai():
                thong_bao(
                    f"üõèÔ∏è S·∫ÆP ƒê·∫æN GI·ªú ({thoi_diem_goc.strftime('%H:%M')})",
                    f"{row['ti√™u ƒë·ªÅ']} (b·∫°n ƒëang n·∫±m)"
                )
                noi("h√£y ƒë·ª©ng d·∫°y n√†o, s·∫Øp ƒë·∫øn gi·ªù th·ª±c hi·ªán l·ªãch r·ªìi nh√©")

#v√≤ng l·∫∑p nh·∫Øc

def vong_lap_nhac():
    while True:
        try:
            kiem_tra_lich()
        except Exception as e:
            print("‚ùå L·ªói ki·ªÉm tra l·ªãch:", e)

        time.sleep(120)  # ki·ªÉm tra m·ªói 2p
#ch·∫°y n·ªÅn

def chay_thread_nhac():
    import threading
    thread = threading.Thread(
        target=vong_lap_nhac,
    )
    thread.start()
    return thread

# xo√° l·ªãch
def xoa():
    noi("H√£y n√≥i t√™n l·ªãch c·∫ßn xo√°")
    noidung = nhangiong()

    df = pd.read_excel(file)

    # ki·ªÉm tra c√≥ t·ªìn t·∫°i kh√¥ng
    ndxoa = df["ti√™u ƒë·ªÅ"].str.lower() == noidung
    if ndxoa.any():
        df = df[~ndxoa]
        df.to_excel(file, index=False)

        noi("ƒê√£ xo√° l·ªãch tr√¨nh")
    else:
        noi("Kh√¥ng t√¨m th·∫•y l·ªãch c·∫ßn x√≥a")
# hi·ªÉn th·ªã
def hienthi():
    df=pd.read_excel("lichtrinh.xlsx")
    print(df)

# Nh·∫≠n d·∫°ng c·∫£m x√∫c th√¥ng qua h√¨nh ·∫£nh v√† gi·ªçng n√≥i
def emotion():
    import joblib

    model = joblib.load("D:/CODER/python/emotion_model/voice_emotion_model.pkl")
    import sounddevice as sd
    import soundfile as sf
    import numpy as np
    import librosa

    def extract_features(file_path, duration=4):
        y, sr = librosa.load(file_path, sr=22050, duration=duration)

        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        mfcc_mean = mfcc.mean(axis=1)

        zcr = librosa.feature.zero_crossing_rate(y).mean()
        rms = librosa.feature.rms(y=y).mean()

        return np.hstack([mfcc_mean, zcr, rms])

    def du_doan_cam_xuc_tu_file(wav_path):
        features = extract_features(wav_path)
        features = np.array(features).reshape(1, -1)

        label = model.predict(features)[0]
        prob = model.predict_proba(features)[0]

        if label == 1:
            return "T√çCH C·ª∞C", prob[1]
        else:
            return "TI√äU C·ª∞C", prob[0]

    def nhan_dien_cam_xuc_tu_micro(duration=4, fs=22050):
        audio = sd.rec(int(duration * fs), samplerate=fs, channels=1)
        sd.wait()

        sf.write("temp.wav", audio, fs)

        return du_doan_cam_xuc_tu_file("temp.wav")
    emotion, confidence = nhan_dien_cam_xuc_tu_micro()
    if emotion=="TI√äU C·ª∞C" and confidence>=0.5:
        noi("xin ch√†o,b·∫°n c√≥ ·ªïn kh√¥ng?")
    elif emotion=="TI√äU C·ª∞C" and confidence<=0.5:
        noi("ng√†y h√¥m nay c·ªßa b·∫°n nh∆∞ th·∫ø n√†o?")
    chaycode()

# k·∫øt n·ªëi v·ªõi gemini th√¥ng qua langgraph
def gemini():
    from dotenv import load_dotenv
    from typing_extensions import TypedDict

    import google.generativeai as genai
    from langgraph.graph import StateGraph, START, END

    # ===== LOAD API KEY =====
    load_dotenv()
    genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

    # ===== INIT GEMINI MODEL =====
    model = genai.GenerativeModel("gemini-2.5-flash")

    # ===== STATE (gi·ªëng Colab) =====
    class ChatState(TypedDict):
        messages: list[str]

    # ===== HUMAN NODE =====
    def human_node(state: ChatState) -> ChatState:
        user_input = input("USER:")

        if user_input.lower() in ["t·∫°m d·ª´ng", "tho√°t"]:
            print("ƒëang t·∫Øt gemini")
            noi("ƒëang t·∫Øt gemini")
            raise KeyboardInterrupt  # tho√°t graph an to√†n

        return {
            "messages": state["messages"] + [user_input]
        }

    # ===== CHATBOT NODE =====
    def chatbot_node(state: ChatState) -> ChatState:
        # l·∫•y 1-2 tin nh·∫Øn g·∫ßn nh·∫•t ƒë·ªÉ l√†m context
        user_input = state["messages"][-1]
        context = ("Tr·∫£ l·ªùi chi ti·∫øt v·ª´a ƒë·ªß, kh√¥ng markdown.\n"+ user_input)

        response = model.generate_content(context,generation_config={
            "max_output_tokens": 256,
            "temperature": 0.7
        })
        reply = response.text.strip()

        print(f"\nü§ñ Chatbot: {reply}\n")
        noi(f"{reply}\n")
        return {
            "messages": state["messages"] + [reply]
        }

    # x√¢y d·ª±ng langgraph v√† c√°c node
    graph = StateGraph(ChatState)

    graph.add_node("human", human_node)
    graph.add_node("chatbot", chatbot_node)

    graph.add_edge(START, "human")
    graph.add_edge("human", "chatbot")
    graph.add_edge("chatbot", END)

    app = graph.compile()

    # khi kh·ªüi ƒë·ªông xong
    if __name__ == "__main__":
        print(" Chatbot Gemini s·∫µn s√†ng\n")
        noi(" Chatbot Gemini s·∫µn s√†ng\n")

        state: ChatState = {"messages": []}

        while True:
            try:
                state = app.invoke(state)
            except KeyboardInterrupt:
                break
chay_thread_nhac()
def chaycode():
    txt='xin ch√†o'
    # ki·ªÉm tra y√™u c·∫ßu
    while True:
        if "hello" or "xin ch√†o" in txt:
                
            noi("ch√†o b·∫°n,xin h·ªèi y√™u c·∫ßu c·ªßa b·∫°n l√† g√¨")
                
            # n√≥i y√™u c·∫ßu
                
            xt =input("y√™u c·∫ßu:")
            if 'x√≥a' in xt:
                hienthi()
                xoa()
            elif 't·∫°m bi·ªát' in xt:
                noi("Ch√†o t·∫°m bi·ªát b·∫°n")
                break
            elif 'h·ªèi ƒë√°p' in xt:
                noi("ƒêang kh·ªüi ƒë·ªông h·ªèi ƒë√°p")
            elif 'xem' in xt:
                noi("ƒêang in l·ªãch tr√¨nh")
                hienthi()
            elif 'gemini' in xt:
                gemini()
            else:
                noi("Xin l·ªói,t√¥i kh√¥ng c√≥ ch·ª©c nƒÉng n√†y")           
emotion()
input("nh·∫•n enter ƒë·ªÉ m·ªü l·∫°i chatbot")

molai()
